\documentclass[twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{authblk}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\setlength{\columnsep}{1cm}
\lstset{
  breaklines=true,
  postbreak=\mbox{{$\hookrightarrow$}\space},
}

\title{A Semi-supervised Method for Training Deep Neural Networks}
\author{Misha Klopukh, Michael Teti, Elan Barenholtz, William Hahn}
\affil{Machine Perception and Cognitive Robotics Laboratory, Florida Atlantic University}
\date{April 2019}

\begin{document}

\maketitle




\begin{abstract}
    Neural networks, specifically deep convolutional networks, with supervised training by gradient descent have become the standard for image recognition tasks. However, this training method is inefficient due to the slow process of updating every weight. When trained from scratch, the model starts with no pre-learned knowledge of the features in the image; thus, it has to develop a representation from randomly initialized weights. We propose a variation of unsupervised sparse-coding to pretrain neural networks that addresses these inefficiencies. XCubed is a new, gradient descent-free algorithm that can be used to initialize CNN weights layer-wise. We show that neural networks pretrained with XCubed train faster, and in some cases, networks with XCubed even outperform standard pretrained networks. This type of training may be imperative for under represented data, allowing new applications of image recognition.
\end{abstract}


\section{Introduction}

Deep Convolutional Networks trained by gradient descent have become the standard for computer vision. This approach has become popular because of the high accuracy and relatively fast training with gradient descent.\cite{alexnet}\cite{Lecun98gradient} However, there are a several fundamental flaws in how we train these networks. An image classification task can be thought of as two tasks, detection -- where image features are identified -- and classification -- where a class is decided based on detected features. These tasks in theory are separate -- you shouldn't need to change your definition of an edge or corner to distinguish a cat from a dog.\cite{cowardtowards} However, in modern deep learning, we allow the network to learn its primitive features while it is learning the task. This is done because we ourselves do not know what primitive features we need to best classify objects. Features learned by gradient descent have long been shown to outperform hand-designed features.\cite{learnvcraft} However, learning these features slows down training significantly, as loss back-propagates through to the first layers and changes them often, even though the layers may have accurate features. This also causes the networks to learn more biases in the training data, and to require more data in order to learn more weights. Other problems with back-propagating through the entire network that arise more in larger networks include the vanishing gradient problem, which causes gradients at the beginning of the network to all be near zero and makes them unable to train properly.\cite{vanishinggradients}\cite{learningproblems} We propose a new way of training a neural network that mitigates these and other problems.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{XCubed_diagram}
    \caption{Diagram of XCubed algorithm}
    \label{fig:diagram}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{Alexnet_diagram}
    \caption{Diagram of Alexnet CNN}
    \label{fig:alex}
\end{figure}
XCubed is an unsupervised, gradient-free, and loss-free algorithm for generating weights for a convolutional neural network. The algorithm, shown in Figure \ref{fig:diagram}, creates a dictionary of features from patches of your data using a repeated compounding method. We used this algorithm to create convolution features for a neural network. We chose the Alexnet\cite{alexnet} architecture, shown in Figure \ref{fig:alex} for the network as it is a relatively small, simple, and commonly used CNN model. In the first iteration of our network, we ran the XCubed algorithm on the Oxford 17 Flowers dataset\cite{flowers} using a patch size of 11x11x3 and set the weights for the first layer of the Alexnet to the output. We then froze that layer and trained the rest of the network with gradient descent. In the second iteration, we went layer by layer running the dataset through the previous layers and running XCubed on the output to generate the weights for that layer. We froze all of the convolutional layers and trained the other layers using gradient descent. In our final iteration, we used the same process but only froze the first three layers. We ran this network on both the Oxford 17 Flowers and ISIC Melanoma datasets.


\begin{figure}[!htb]
\begin{equation}
    a = \lambda(\text{NC}(W^\prime X))^{\circ 3}
\end{equation}
\begin{equation}
    W = \text{NC}(W + (X-Wa)a^\prime)
\end{equation}
\caption{XCubed update function}
\label{equ:xcubedupdate}
\end{figure}





\section{Results}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{X3GRAPH}
    \caption{Accuracy of various training methods for Alexnet on 17 Flowers}
    \label{fig:netspeedup}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{x3filters}
    \caption{Filters produced by XCubed}
    \label{fig:x3weights}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{trainedfet}
    \caption{Filters learned by Alexnet's first layer}
    \label{fig:learnedweights}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{x3vpretrained}
    \caption{XCubed filters on ISIC Melanoma dataset}
    \label{fig:melanomacompare}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=.8\linewidth]{melafet}
    \caption{XCubed filters on ISIC Melanoma dataset}
    \label{fig:melanoma}
\end{figure}
The first Alexnet network had its first layer pretrained with XCubed and frozen, and it trained significantly faster than the baseline Alexnet, achieving 99\% accuracy 10 epochs before the regular Alexnet, which was at 90\% accuracy at the time. The second iteration Alexnet did achieve 99\% accuracy, but, although the network started off training faster, it ended up much slower than the baseline due to its inability to train its convolution layers. The Alexnet network where all of the convolutional layers are trained with XCubed and the first three layers were frozen trained much faster than a standard Alexnet or an Alexnet where the first layer is trained with XCubed, with the network reaching 99\% accuracy in just 8 epochs, as shown in Figure \ref{fig:netspeedup}. The training is more comparable to an Alexnet pretrained on imagenet, which starts off with a higher accuracy and reaches 99\% just 1 epoch before at 7 epochs. When run on the Oxford 17 Flowers dataset, the XCubed algorithm produces the first layer filters shown in Figure \ref{fig:x3weights} after 1000 iterations. Alexnet pretrained on imagenet and trained on 17 Flowers produces similar filters, shown in figure \ref{fig:learnedweights}. However, Alexnet had to train fully, while XCubed ran in under 3 seconds on the dataset.

On the ISIC melanoma challenge dataset\cite{melanoma1}\cite{melanoma2}, our model achieved an accuracy of 71\% in just 35 epochs using a simple Alexnet. For reference, the highest accuracy achieved in the 2018 contest without external data was 84\%, and that is with an ensemble of networks. This model also took less than 3 hours to run on an Intel i5 machine with a Titan X GPU, with the XCubed pretraining only taking 63 minutes and 46 seconds using only the CPU. The network in fact outperforms an imagenet pretrained Alexnet significantly, as shown in Figure \ref{fig:melanomacompare}. Interestingly, the first layer features produced by the XCubed algorithm were significantly different from the first layer features for 17 flowers. The features, shown in Figure \ref{fig:melanoma} had much more texture features in them such as checker patterns.
\section{Conclusion}
These findings show that XCubed is a viable option for speeding up neural network training, and these speedups are comparable to pretraining. The melanoma result shows that XCubed can in fact outperform pretraining on datasets that have different properties and thus need different features. This might indicate XCubed utility for audio, sensory, and other non-image datasets. Potential future findings with this algorithm may include using the algorithm to pretrain generators in GANs, RNNs, or other types of artificial neural networks and applying this method to medical and non-image datasets.
\section{Pseudocode}
\begin{lstlisting}[language=Python]
import numpy as np
from numpy import matmul as mm
from np.random import randint, randn
from np.linalg import svd
from scipy.io import imread
import matplotlib.pyplot as plt

def normalize_columns(X):
    return mm(X, np.diag(1./(np.sqrt(np.sum(a**2, axis=0))+1e-6)))

def get_batch(X, patchshape, batch_size=200):
    ix = randint(0,X.shape[1]-patchshape[0])
    iy = randint(0,X.shape[2]-patchshape[1])
    iz = randint(0,X.shape[3]-patchshape[2]) if patchshape[2] != X.shape[3] else 0
    B = X[randint(0,X.shape[0], size=batch_size),ix:ix + patchshape[0],iy:iy + patchshape[1],iz:iz + patchshape[2]].reshape(batch_size, patchshape[0]*patchshape[1]*patchshape[2])
    B = B.T
    B = B - np.mean(B, axis=0)
    U,S,V = svd(mm(B, B.T))
    ZCAMatrix = mm(U, mm(np.diag(1.0/np.sqrt(S+1e-5)),U.T))
    B = mm(B, ZCAMatrix)
    return B

def train_XCubed(W, dataset, patchshape, batch_size, iterations):
    for i in range(iterations):
        batch = get_batch(X, patchshape, batch_size=batch_size)
        W = normalize_columns(W)
        a = 0.5*normalize_columns(mm(W.T, batch))**3
        W += mm((batch - mm(W,a)),a.T)
    return W

import glob
filelist = glob.glob('data/*.png')
Data = np.array([imread(fname) for fname in filelist])

Filters = randn(363,64)
Filters = train_XCubed(Filters, Data, (11,11,3), 200, 1000)
Filters = Filters.transpose(1,0).reshape(64,11,11,3)
np.save('filters.npy', Filters)

fig, axs = plt.subplots(8, 8)
fig.suptitle('Features')
plt.axes('off')
for i in range(8):
    for j in range(8):
        axs[i][j].imshow(Filters[i*8+j])
plt.savefig('filters.png')
plt.show()
\end{lstlisting}
\nocite{*}
\bibliographystyle{unsrt}
\bibliography{references}
\end{document}